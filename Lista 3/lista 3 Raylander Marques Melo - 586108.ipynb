{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37122d68",
   "metadata": {},
   "source": [
    "# Nome: Raylander Marques Melo\n",
    "# Matrícula: 586108"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b3fe4e",
   "metadata": {},
   "source": [
    "# Questão 1: Considere o conjunto de dados disponível em kc2.csv, organizado em 22 colunas, sendo as 21 primeiras colunas os atributos e a última coluna a saída. Os 21 atributos são referentes à caracterização de códigos-fontes para processamento de dados na NASA. A saída é a indicação de ausência (0) ou existência (1) de defeitos (os dados foram balanceados via subamostragem). Maiores detalhes sobre os dados podem ser conferidos em https://www.openml.org/search?type=data&sort=runs&id=1063&status=active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "12d7cb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.2.6)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: Jinja2 in ./.venv/lib/python3.12/site-packages (3.1.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from Jinja2) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy scikit-learn matplotlib pandas Jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6452c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c711a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('kc2.csv', delimiter=',')\n",
    "x = data[:,:-1]\n",
    "y = data[:,-1].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "52d65095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(X, y, k, random_state=42):\n",
    "    # Embaralha os dados\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Divide os dados em k folds\n",
    "    folds = np.array_split(indices, k)\n",
    "    \n",
    "    for i in range(k):\n",
    "        # Cria os conjuntos de treino e teste\n",
    "        test_indices = folds[i]\n",
    "        train_indices = np.concatenate(folds[:i] + folds[i+1:])\n",
    "        X_train, X_test = X[train_indices], X[test_indices]\n",
    "        y_train, y_test = y[train_indices], y[test_indices]\n",
    "        \n",
    "        yield X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2319f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliza(X):\n",
    "    # Calculando a média e a distribuição \n",
    "    mean = X.sum(axis = 0) / X.shape[0]\n",
    "    std = np.sqrt(((X-mean)**2).sum(axis=0)/(X.shape[0]-1))\n",
    "    std[std == 0] = 1  # Evita divisão por zero\n",
    "    # Normaliza os dados\n",
    "    return ((X - mean) / std), mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eef565b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_loop(x, y, model_class, grid, internal_kfold=10, scale_flag=True, verbose=True, random_state=12345):\n",
    "    param_names = list(grid.keys())\n",
    "    grid_search = np.meshgrid(*grid.values())\n",
    "    grid_search = np.hstack([ np.atleast_2d(g.ravel()).T for g in grid_search ], dtype='object')\n",
    "    \n",
    "    for i, params in enumerate(grid_search):\n",
    "        param_dict = dict(zip(param_names, params))\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Testing parameters: {param_dict}\")\n",
    "        \n",
    "        fold_scores = []\n",
    "        \n",
    "        for x_train, x_test, y_train, y_test in kfold(x, y, k=internal_kfold, random_state=random_state):\n",
    "                        \n",
    "            if scale_flag:\n",
    "                x_train, mean, std = normaliza(x_train)\n",
    "                x_test = (x_test - mean) / std\n",
    "                model = model_class(**param_dict)\n",
    "            else:\n",
    "                model = model_class(**param_dict)\n",
    "            \n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred = model.predict(x_test)\n",
    "            fold_scores.append(accuracy_score(y_test, y_pred))\n",
    "        \n",
    "        yield param_dict, fold_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8fb40a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nested_cv(x, y, model_class, grid, external_kfold=5, scale_flag=True, verbose=True, random_state=12345):\n",
    "    param_names = list(grid.keys())\n",
    "    grid_search = np.meshgrid(*grid.values())\n",
    "    grid_search = np.hstack([ np.atleast_2d(g.ravel()).T for g in grid_search ], dtype='object')\n",
    "    \n",
    "    # Dicionário para armazenar métricas por combinação de parâmetros\n",
    "    results = defaultdict(lambda: {'acc': [], 'rec': [], 'prec': [], 'f1': []})\n",
    "\n",
    "    for x_train, x_test, y_train, y_test in kfold(x, y, k=external_kfold, random_state=random_state):\n",
    " \n",
    "        for i, params in enumerate(grid_search):\n",
    "            param_dict = dict(zip(param_names, params))\n",
    "            param_key = str(param_dict)  # Chave para agrupar resultados\n",
    "\n",
    "            # if verbose:\n",
    "            #     print(f\"[Fold {cont}] Testing parameters: {param_dict}\")\n",
    "            \n",
    "            if scale_flag:\n",
    "                x_train, mean, std = normaliza(x_train)\n",
    "                x_test = (x_test - mean) / std\n",
    "                model = model_class(**param_dict)\n",
    "            else:\n",
    "                model = model_class(**param_dict)\n",
    "            \n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred = model.predict(x_test)\n",
    "\n",
    "            results[param_key]['acc'].append(accuracy_score(y_test, y_pred))\n",
    "            results[param_key]['rec'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "            results[param_key]['prec'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "            results[param_key]['f1'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "\n",
    "    print(f\"{'Parâmetros':<43} | {'Accuracy':^15} | {'Recall':^15} | {'Precision':^15} | {'F1-score':^15}\")\n",
    "\n",
    "    # Calcula média e desvio padrão das métricas por parâmetro\n",
    "    avg_results = {}\n",
    "    for param_key, metric_vals in results.items():\n",
    "        avg_results[param_key] = {\n",
    "            'mean_acc': np.mean(metric_vals['acc']),\n",
    "            'std_acc': np.std(metric_vals['acc']),\n",
    "            'mean_rec': np.mean(metric_vals['rec']),\n",
    "            'std_rec': np.std(metric_vals['rec']),\n",
    "            'mean_prec': np.mean(metric_vals['prec']),\n",
    "            'std_prec': np.std(metric_vals['prec']),\n",
    "            'mean_f1': np.mean(metric_vals['f1']),\n",
    "            'std_f1': np.std(metric_vals['f1']),\n",
    "        }\n",
    "\n",
    "        if verbose:\n",
    "            \n",
    "            print('-' * 115)\n",
    "            print(f\"{param_key:<43} | \"\n",
    "                f\"{avg_results[param_key]['mean_acc']:.4f} ± {avg_results[param_key]['std_acc']:.4f} | \"\n",
    "                f\"{avg_results[param_key]['mean_rec']:.4f} ± {avg_results[param_key]['std_rec']:.4f} | \"\n",
    "                f\"{avg_results[param_key]['mean_prec']:.4f} ± {avg_results[param_key]['std_prec']:.4f} | \"\n",
    "                f\"{avg_results[param_key]['mean_f1']:.4f} ± {avg_results[param_key]['std_f1']:.4f}\")\n",
    "            \n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12f668",
   "metadata": {},
   "source": [
    "## Questão 1 a) Considerando uma validação cruzada em 10 folds, avalie modelos de classificação binária nos dados em questão. Para tanto, use as abordagens abaixo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0d726e",
   "metadata": {},
   "source": [
    "### – KNN (escolha k = 1 e k = 5, distância Euclidiana e Mahalonobis, totalizando 4 combinações);\n",
    "### – Árvore de decisão (você pode usar uma implementação já existente, como a do scikit-learn, com índices de impureza de gini e entropia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "00e2defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular distância Euclidiana\n",
    "def euclidean_distance(p1, p2):\n",
    "    soma = 0\n",
    "    for i in range(len(p1)):\n",
    "        soma += (p1[i] - p2[i]) ** 2\n",
    "    return soma ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7f11edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a distância de Mahalonobis\n",
    "def mahalanobis_distance(p1, p2, cov_inv):\n",
    "    diff = p1 - p2\n",
    "    return np.sqrt(np.dot(np.dot(diff, cov_inv), diff.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a88a5bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para encontrar os K vizinhos mais próximos\n",
    "def get_neighbors(train_data, train_labels, test_point, k, metric='euclidean'):\n",
    "    distancias = []\n",
    "    for i in range(len(train_data)):\n",
    "        if metric == 'mahalanobis':\n",
    "            cov_inv = np.linalg.inv(np.cov(train_data.T))\n",
    "            distancia = mahalanobis_distance(test_point, train_data[i], cov_inv)\n",
    "        elif metric == 'euclidean':\n",
    "            distancia = euclidean_distance(test_point, train_data[i])\n",
    "        distancias.append((distancia, train_labels[i]))\n",
    "    \n",
    "    distancias.sort()  # Ordena pela menor distância\n",
    "    vizinhos = distancias[:k]\n",
    "    return [label for (_, label) in vizinhos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c298fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para determinar a classe mais comum entre os vizinhos\n",
    "def vote(vizinhos):\n",
    "    contagem = {}\n",
    "    for label in vizinhos:\n",
    "        contagem[label] = contagem.get(label, 0) + 1\n",
    "    return max(contagem, key=contagem.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7405fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função principal do KNN\n",
    "class KNN:\n",
    "    def __init__(self, k=2, metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.train_data = X\n",
    "        self.train_labels = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        return knn_predict(self.train_data, self.train_labels, X, self.k, self.metric)\n",
    "    \n",
    "def knn_predict(train_data, train_labels, test_data, k=2, metric='euclidean'):\n",
    "    predicoes = []\n",
    "    for ponto in test_data:\n",
    "        vizinhos = get_neighbors(train_data, train_labels, ponto, k,metric=metric)\n",
    "        classe = vote(vizinhos)\n",
    "        predicoes.append(classe)\n",
    "    return predicoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38785969",
   "metadata": {},
   "source": [
    "## Questão 1 b) Para cada modelo criado, reporte valor médio e desvio padrão das métricas de acurácia, revocação, precisão e F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3de5cff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                      KNN\n",
      "\n",
      "Parâmetros                                  |    Accuracy     |     Recall      |    Precision    |    F1-score    \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "{'k': 1, 'metric': 'euclidean'}             | 0.7578 ± 0.1134 | 0.7613 ± 0.1124 | 0.7655 ± 0.1184 | 0.7541 ± 0.1129\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "{'k': 5, 'metric': 'euclidean'}             | 0.7903 ± 0.1194 | 0.7945 ± 0.1188 | 0.7983 ± 0.1203 | 0.7871 ± 0.1187\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "{'k': 1, 'metric': 'mahalanobis'}           | 0.7108 ± 0.0922 | 0.7121 ± 0.0900 | 0.7222 ± 0.0912 | 0.7029 ± 0.0921\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "{'k': 5, 'metric': 'mahalanobis'}           | 0.7712 ± 0.0852 | 0.7697 ± 0.0856 | 0.7798 ± 0.0839 | 0.7639 ± 0.0862\n",
      "\n",
      "\n",
      "\n",
      "                                                      DT\n",
      "\n",
      "Parâmetros                                  |    Accuracy     |     Recall      |    Precision    |    F1-score    \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "{'criterion': 'gini', 'max_depth': None}    | 0.7348 ± 0.1042 | 0.7366 ± 0.1037 | 0.7518 ± 0.1121 | 0.7287 ± 0.1026\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "{'criterion': 'entropy', 'max_depth': None} | 0.7195 ± 0.1115 | 0.7187 ± 0.1070 | 0.7268 ± 0.1120 | 0.7117 ± 0.1132\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executando o KNN com os dados de treino e teste\n",
    "external_kfold = 10\n",
    "\n",
    "methods_summary = {'KNN': {'class': KNN, 'scale': True},\n",
    "                   'DT' : {'class': DecisionTreeClassifier, 'scale': False}}\n",
    "\n",
    "# KNN\n",
    "methods_summary['KNN']['grid'] = {'k': [1, 5],         # k - número de vizinhos\n",
    "                                  'metric': ['euclidean','mahalanobis']}        # metric            \n",
    "# Decision Tree\n",
    "methods_summary['DT']['grid'] = {'criterion': ['gini', 'entropy'],                # criterion\n",
    "                                 'max_depth': [None]} # max_depth\n",
    "\n",
    "trained_models = {}\n",
    "for method, info in methods_summary.items():\n",
    "    print(f\"\\n                                                      {method}\\n\")\n",
    "    run_nested_cv(x=x, y=y, model_class=info['class'],\n",
    "                                        grid=info['grid'], scale_flag=info['scale'],\n",
    "                                        external_kfold=external_kfold, verbose=True, random_state=42)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
