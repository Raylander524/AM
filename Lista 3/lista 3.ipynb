{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b3fe4e",
   "metadata": {},
   "source": [
    "# Questão 1: Considere o conjunto de dados disponível em kc2.csv, organizado em 22 colunas, sendo as 21 primeiras colunas os atributos e a última coluna a saída. Os 21 atributos são referentes à caracterização de códigos-fontes para processamento de dados na NASA. A saída é a indicação de ausência (0) ou existência (1) de defeitos (os dados foram balanceados via subamostragem). Maiores detalhes sobre os dados podem ser conferidos em https://www.openml.org/search?type=data&sort=runs&id=1063&status=active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "12d7cb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.2.6)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Collecting Jinja2\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Installing collected packages: MarkupSafe, Jinja2\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [Jinja2]━━━━\u001b[0m \u001b[32m1/2\u001b[0m [Jinja2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Jinja2-3.1.6 MarkupSafe-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy scikit-learn matplotlib pandas Jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6452c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c711a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('kc2.csv', delimiter=',')\n",
    "x = data[:,:-1]\n",
    "y = data[:,-1].astype(int)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52d65095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(X, y, k, random_state=42):\n",
    "    # Embaralha os dados\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    # Divide os dados em k folds\n",
    "    folds = np.array_split(indices, k)\n",
    "    \n",
    "    for i in range(k):\n",
    "        # Cria os conjuntos de treino e teste\n",
    "        test_indices = folds[i]\n",
    "        train_indices = np.concatenate(folds[:i] + folds[i+1:])\n",
    "        X_train, X_test = X[train_indices], X[test_indices]\n",
    "        y_train, y_test = y[train_indices], y[test_indices]\n",
    "        \n",
    "        yield X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2319f1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normaliza(X):\n",
    "    # Calculando a média e a distribuição \n",
    "    mean = X.sum(axis = 0) / X.shape[0]\n",
    "    std = np.sqrt(((X-mean)**2).sum(axis=0)/(X.shape[0]-1))\n",
    "    std[std == 0] = 1  # Evita divisão por zero\n",
    "    # Normaliza os dados\n",
    "    return ((X - mean) / std), mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eef565b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_loop(x, y, model_class, grid, internal_kfold=10, scale_flag=True, verbose=True, random_state=12345):\n",
    "    param_names = list(grid.keys())\n",
    "    grid_search = np.meshgrid(*grid.values())\n",
    "    grid_search = np.hstack([ np.atleast_2d(g.ravel()).T for g in grid_search ], dtype='object')\n",
    "    \n",
    "    for i, params in enumerate(grid_search):\n",
    "        param_dict = dict(zip(param_names, params))\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Testing parameters: {param_dict}\")\n",
    "        \n",
    "        fold_scores = []\n",
    "        \n",
    "        for x_train, x_test, y_train, y_test in kfold(x, y, k=internal_kfold, random_state=random_state):\n",
    "                        \n",
    "            if scale_flag:\n",
    "                x_train, mean, std = normaliza(x_train)\n",
    "                x_test, mean_test, mean_test = normaliza(x_test)\n",
    "                model = model_class(**param_dict)\n",
    "            else:\n",
    "                model = model_class(**param_dict)\n",
    "            \n",
    "            model.fit(x_train, y_train)\n",
    "            y_pred = model.predict(x_test)\n",
    "            fold_scores.append(accuracy_score(y_test, y_pred))\n",
    "        \n",
    "        yield param_dict, fold_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8fb40a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nested_cv(x, y, model_class, grid, external_kfold=5, internal_kfold=5, scale_flag=True, verbose=True, random_state=12345):\n",
    "    metrics = {'acc': [], 'rec': [], 'prec': [], 'f1': []}\n",
    "\n",
    "    best_model = None\n",
    "    best_score = -np.inf\n",
    "    \n",
    "    for x_train, x_test, y_train, y_test in kfold(x, y, k=external_kfold, random_state=random_state):\n",
    "\n",
    "        for params, fold_scores in inner_loop(x_train, y_train, model_class, grid, internal_kfold, scale_flag, verbose, random_state):\n",
    "            mean_score = np.mean(fold_scores)\n",
    "            std_score = np.std(fold_scores)\n",
    "            if verbose:\n",
    "                print(f\"Mean accuracy for parameters {params}: {mean_score:.4f}\")\n",
    "                print(f\"Standard deviation: {std_score:.4f}\")\n",
    "\n",
    "            if mean_score > best_score:\n",
    "                best_score = mean_score\n",
    "                best_model = model_class(**params)\n",
    "                \n",
    "                best_model.fit(x_train, y_train)\n",
    "\n",
    "        y_pred = best_model.predict(x_test)\n",
    "        metrics['acc'].append(accuracy_score(y_test, y_pred))\n",
    "        metrics['rec'].append(recall_score(y_test, y_pred, average='macro'))\n",
    "        metrics['prec'].append(precision_score(y_test, y_pred, average='macro'))\n",
    "        metrics['f1'].append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "                           \n",
    "    return metrics, best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf12f668",
   "metadata": {},
   "source": [
    "## Questão 1 a) Considerando uma validação cruzada em 10 folds, avalie modelos de classificação binária nos dados em questão. Para tanto, use as abordagens abaixo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0d726e",
   "metadata": {},
   "source": [
    "### – KNN (escolha k = 1 e k = 5, distância Euclidiana e Mahalonobis, totalizando 4 combinações);\n",
    "### – Árvore de decisão (você pode usar uma implementação já existente, como a do scikit-learn, com índices de impureza de gini e entropia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00e2defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular distância Euclidiana\n",
    "def euclidean_distance(p1, p2):\n",
    "    soma = 0\n",
    "    for i in range(len(p1)):\n",
    "        soma += (p1[i] - p2[i]) ** 2\n",
    "    return soma ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f11edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular a distância de Mahalonobis\n",
    "def mahalanobis_distance(p1, p2, cov_inv):\n",
    "    diff = p1 - p2\n",
    "    return np.sqrt(np.dot(np.dot(diff, cov_inv), diff.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a88a5bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para encontrar os K vizinhos mais próximos\n",
    "def get_neighbors(train_data, train_labels, test_point, k, metric='euclidean'):\n",
    "    distancias = []\n",
    "    for i in range(len(train_data)):\n",
    "        if metric == 'mahalanobis':\n",
    "            cov_inv = np.linalg.inv(np.cov(train_data.T))\n",
    "            distancia = mahalanobis_distance(test_point, train_data[i], cov_inv)\n",
    "        elif metric == 'euclidean':\n",
    "            distancia = euclidean_distance(test_point, train_data[i])\n",
    "        distancias.append((distancia, train_labels[i]))\n",
    "    \n",
    "    distancias.sort()  # Ordena pela menor distância\n",
    "    vizinhos = distancias[:k]\n",
    "    return [label for (_, label) in vizinhos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c298fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para determinar a classe mais comum entre os vizinhos\n",
    "def vote(vizinhos):\n",
    "    contagem = {}\n",
    "    for label in vizinhos:\n",
    "        contagem[label] = contagem.get(label, 0) + 1\n",
    "    return max(contagem, key=contagem.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7405fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função principal do KNN\n",
    "class KNN:\n",
    "    def __init__(self, k=2, metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.train_data = X\n",
    "        self.train_labels = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        return knn_predict(self.train_data, self.train_labels, X, self.k, self.metric)\n",
    "    \n",
    "def knn_predict(train_data, train_labels, test_data, k=2, metric='euclidean'):\n",
    "    predicoes = []\n",
    "    for ponto in test_data:\n",
    "        vizinhos = get_neighbors(train_data, train_labels, ponto, k,metric=metric)\n",
    "        classe = vote(vizinhos)\n",
    "        predicoes.append(classe)\n",
    "    return predicoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3de5cff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[KNN] Running nested K-fold...\n",
      "\n",
      "[DT] Running nested K-fold...\n"
     ]
    }
   ],
   "source": [
    "# Executando o KNN com os dados de treino e teste\n",
    "external_kfold = 10\n",
    "internal_kfold = 10\n",
    "\n",
    "methods_summary = {'KNN': {'class': KNN, 'scale': True},\n",
    "                   'DT' : {'class': DecisionTreeClassifier, 'scale': False}}\n",
    "\n",
    "# KNN\n",
    "methods_summary['KNN']['grid'] = {'k': [1, 5],         # k - número de vizinhos\n",
    "                                  'metric': ['euclidean','mahalanobis']}        # metric            \n",
    "# Decision Tree\n",
    "methods_summary['DT']['grid'] = {'criterion': ['gini', 'entropy'],                # criterion\n",
    "                                 'max_depth': [2, 3, 4, 5, 6, 7, 8, 9, 10, None]} # max_depth\n",
    "\n",
    "trained_models = {}\n",
    "for method, info in methods_summary.items():\n",
    "    print(f\"\\n[{method}] Running nested K-fold...\")\n",
    "    metrics, best_model = run_nested_cv(x=x, y=y, model_class=info['class'],\n",
    "                                        grid=info['grid'], scale_flag=info['scale'],\n",
    "                                        external_kfold=external_kfold, internal_kfold=internal_kfold, verbose=False, random_state=42)\n",
    "    trained_models[method] = {'metrics': metrics, 'model': best_model}\n",
    "\n",
    "# Results\n",
    "results = { method : info['metrics'] for method, info in trained_models.items() }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38785969",
   "metadata": {},
   "source": [
    "## Questão 1 b) Para cada modelo criado, reporte valor médio e desvio padrão das métricas de acurácia, revocação, precisão e F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8714969b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_76e1d_row1_col0, #T_76e1d_row1_col1, #T_76e1d_row1_col2, #T_76e1d_row1_col3 {\n",
       "  font-weight: bold;\n",
       "  color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_76e1d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_76e1d_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_76e1d_level0_col1\" class=\"col_heading level0 col1\" >Recall</th>\n",
       "      <th id=\"T_76e1d_level0_col2\" class=\"col_heading level0 col2\" >Precision</th>\n",
       "      <th id=\"T_76e1d_level0_col3\" class=\"col_heading level0 col3\" >F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_76e1d_level0_row0\" class=\"row_heading level0 row0\" >KNN</th>\n",
       "      <td id=\"T_76e1d_row0_col0\" class=\"data row0 col0\" >80.45% +- 8.06%</td>\n",
       "      <td id=\"T_76e1d_row0_col1\" class=\"data row0 col1\" >80.77% +- 7.98%</td>\n",
       "      <td id=\"T_76e1d_row0_col2\" class=\"data row0 col2\" >80.73% +- 7.94%</td>\n",
       "      <td id=\"T_76e1d_row0_col3\" class=\"data row0 col3\" >80.24% +- 8.01%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76e1d_level0_row1\" class=\"row_heading level0 row1\" >DT</th>\n",
       "      <td id=\"T_76e1d_row1_col0\" class=\"data row1 col0\" >81.36% +- 6.91%</td>\n",
       "      <td id=\"T_76e1d_row1_col1\" class=\"data row1 col1\" >81.44% +- 7.00%</td>\n",
       "      <td id=\"T_76e1d_row1_col2\" class=\"data row1 col2\" >81.54% +- 6.90%</td>\n",
       "      <td id=\"T_76e1d_row1_col3\" class=\"data row1 col3\" >81.03% +- 6.92%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x720ac94be7e0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(results).T.map(lambda x: f\"{np.mean(x):.2%} +- {1.96*np.std(x)/np.sqrt(len(x)):.2%}\")\n",
    "table.columns = ['Accuracy', 'Recall', 'Precision', 'F1-score']\n",
    "table.index = results.keys()\n",
    "def extract_from_text(text):\n",
    "    return float(text.split('%')[0])\n",
    "table.style.apply(lambda col: [ 'font-weight:bold; color:red' if extract_from_text(x)==col.apply(extract_from_text).max() else '' for x in col ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
